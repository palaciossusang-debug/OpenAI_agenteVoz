{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d9af68ce",
      "metadata": {
        "id": "d9af68ce"
      },
      "source": [
        "\n",
        "# Pr√°ctica 1 ‚Äî **Embeddings & B√∫squeda Sem√°ntica**  \n",
        "**Sesi√≥n 4 ¬∑ 2025-09-29**\n",
        "\n",
        "**Objetivo:** Construir un *notebook* que:\n",
        "1) Genere *embeddings* de un peque√±o corpus,  \n",
        "2) Cree un √≠ndice de b√∫squeda sem√°ntica,  \n",
        "3) Permita realizar consultas,  \n",
        "4) Evalue brevemente la relevancia de los resultados.\n",
        "\n",
        "---\n",
        "## Caso de uso: *Asistente de Conocimiento Interno (FAQ corporativa)*\n",
        "\n",
        "Imaginemos que trabajas en una empresa de tecnolog√≠a con varias √°reas (TI, RR. HH., Legal, Datos). Los colaboradores realizan preguntas recurrentes: **pol√≠ticas de vacaciones**, **acceso a VPN**, **solicitud de equipos**, **alta en plataformas cloud**, **soporte a BI**, etc.  \n",
        "El objetivo es construir un prototipo de **b√∫squeda sem√°ntica** que encuentre las respuestas m√°s relevantes a partir de un conjunto corto de **art√≠culos/FAQs internos**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "227453b8",
      "metadata": {
        "id": "227453b8"
      },
      "source": [
        "## 1) Importaciones y utilidades"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d6c25277",
      "metadata": {
        "id": "d6c25277"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os, re, math, json, random, unicodedata\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Tuple, Dict\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "def normalize_text(s: str) -> str:\n",
        "    s = s.lower().strip()\n",
        "    s = ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
        "    s = re.sub(r'[^a-z0-9√°√©√≠√≥√∫√±√º\\s]', ' ', s)\n",
        "    s = re.sub(r'\\s+', ' ', s).strip()\n",
        "    return s\n",
        "\n",
        "# Peque√±a lista de stopwords ES (evitamos descargar NLTK)\n",
        "STOPWORDS = set('''de la que el en y a los del se las por un para con no una su al lo como mas pero sus le ya o fue ha si porque muy sin sobre tambien me hasta hay donde quienes cual cuales cuando desde todo nos durante cada contra entre tras antes despues mi tus tus\n",
        "esto esta estas estos ese esa esos esas aquel aquella aquellos aquellas soy eres es somos son estoy estas esta estamos estan\n",
        "ser estar tener hace hacen hacer hacia podria puedes puede pueden podria deber debemos deben debo debo\n",
        "ti tu usted ustedes nosotros nosotras ellos ellas su sus mio mia mios mias tuyo tuya tuyos tuyas suyo suya suyos suyas\n",
        "mi mis nuestro nuestra nuestros nuestras vuestro vuestra vuestros vuestras\n",
        "que quien quienes cual cuales cuanto cuanta cuantos cuantas donde adonde como cuando cuanto\n",
        "'''.split())\n",
        "\n",
        "def remove_stopwords(text: str) -> str:\n",
        "    tokens = normalize_text(text).split()\n",
        "    tokens = [t for t in tokens if t not in STOPWORDS and len(t) > 2]\n",
        "    return ' '.join(tokens)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25b0198e",
      "metadata": {
        "id": "25b0198e"
      },
      "source": [
        "## 2) Dataset de FAQs internas (corpus de documentos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a2ab568",
      "metadata": {
        "id": "0a2ab568"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Creamos un mini-corpus de art√≠culos/FAQs internas (id, titulo, contenido)\n",
        "docs = [\n",
        "    (1, \"Pol√≠tica de Vacaciones\", \"\"\"\n",
        "    La empresa ofrece 12 d√≠as de vacaciones el primer a√±o, con incremento gradual por antig√ºedad.\n",
        "    Para solicitar vacaciones debes ingresar a la plataforma de RRHH con 15 d√≠as de anticipaci√≥n.\n",
        "    \"\"\"),\n",
        "    (2, \"Acceso a VPN corporativa\", \"\"\"\n",
        "    Para conectarte a la VPN necesitas un usuario activo, MFA y el cliente OpenVPN.\n",
        "    Si tienes problemas, abre un ticket al √°rea de TI incluyendo sistema operativo y ubicaci√≥n.\n",
        "    \"\"\"),\n",
        "    (3, \"Solicitud de Equipo de C√≥mputo\", \"\"\"\n",
        "    Los equipos (laptop/desktop) se solicitan a TI v√≠a formulario interno.\n",
        "    Se requiere aprobaci√≥n del gerente y se asigna un activo con etiqueta y p√≥liza de garant√≠a.\n",
        "    \"\"\"),\n",
        "    (4, \"Alta en Plataformas Cloud (GCP/Azure/AWS)\", \"\"\"\n",
        "    El alta en nubes p√∫blicas requiere curso de seguridad, aceptaci√≥n de pol√≠ticas y creaci√≥n de cuentas con\n",
        "    privilegios m√≠nimos. Solicita acceso especificando proyecto y rol necesario.\n",
        "    \"\"\"),\n",
        "    (5, \"Soporte a Business Intelligence (BI)\", \"\"\"\n",
        "    Para crear o actualizar dashboards en Looker/Power BI, env√≠a un requerimiento con m√©tricas,\n",
        "    fuentes de datos y periodicidad. El equipo de Datos eval√∫a SLA y complejidad.\n",
        "    \"\"\"),\n",
        "    (6, \"Pol√≠tica de Home Office\", \"\"\"\n",
        "    El trabajo remoto es h√≠brido: 3 d√≠as en oficina y 2 en casa. Las excepciones requieren autorizaci√≥n de RRHH.\n",
        "    Se recomienda conexi√≥n estable y uso de VPN para recursos internos.\n",
        "    \"\"\"),\n",
        "    (7, \"Onboarding y Credenciales\", \"\"\"\n",
        "    En tu primera semana recibir√°s credenciales de correo, gestor de contrase√±as y acceso a gestor de identidades.\n",
        "    Completa el curso de phishing y activa MFA en todas las aplicaciones.\n",
        "    \"\"\"),\n",
        "    (8, \"Procesos de Soporte TI\", \"\"\"\n",
        "    Los tickets se abren en el portal de soporte. Prioridades: cr√≠tica, alta, media, baja.\n",
        "    Incidentes cr√≠ticos requieren puente de guerra y notificaci√≥n a ciberseguridad.\n",
        "    \"\"\"),\n",
        "    (9, \"Pol√≠tica de Seguridad de la Informaci√≥n\", \"\"\"\n",
        "    Todos los colaboradores deben seguir las gu√≠as de clasificaci√≥n de datos, uso de contrase√±as robustas y reporte\n",
        "    de incidentes. El cifrado es obligatorio en equipos port√°tiles.\n",
        "    \"\"\"),\n",
        "    (10, \"Accesos a Bases de Datos\", \"\"\"\n",
        "    Para acceder a bases de datos productivas se requiere justificaci√≥n, ventana de mantenimiento y aprobaci√≥n\n",
        "    del due√±o del dato. Se recomienda uso de cuentas de solo lectura.\n",
        "    \"\"\"),\n",
        "]\n",
        "\n",
        "df = pd.DataFrame(docs, columns=[\"id\",\"titulo\",\"contenido\"])\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6bff03ba",
      "metadata": {
        "id": "6bff03ba"
      },
      "source": [
        "## 3) Limpieza y normalizaci√≥n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "459bf3c7",
      "metadata": {
        "id": "459bf3c7"
      },
      "outputs": [],
      "source": [
        "\n",
        "df[\"texto_proc\"] = df[\"contenido\"].apply(remove_stopwords)\n",
        "df[[\"id\",\"titulo\",\"texto_proc\"]].head(10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "111ade26",
      "metadata": {
        "id": "111ade26"
      },
      "source": [
        "## 4) Embeddings con **TF‚ÄëIDF**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72ce8e1b",
      "metadata": {
        "id": "72ce8e1b"
      },
      "outputs": [],
      "source": [
        "\n",
        "tfidf = TfidfVectorizer(min_df=1, max_df=0.95, ngram_range=(1,2))\n",
        "X_tfidf = tfidf.fit_transform(df[\"texto_proc\"])\n",
        "X_tfidf.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d144762",
      "metadata": {
        "id": "8d144762"
      },
      "source": [
        "## 5) Reducci√≥n sem√°ntica con **LSA (SVD truncado)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1528470",
      "metadata": {
        "id": "b1528470"
      },
      "outputs": [],
      "source": [
        "\n",
        "n_components = 128 if X_tfidf.shape[1] >= 128 else max(2, min(64, X_tfidf.shape[1]-1))\n",
        "svd = TruncatedSVD(n_components=n_components, random_state=42)\n",
        "X_lsa = svd.fit_transform(X_tfidf)\n",
        "X_lsa.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cafbf099",
      "metadata": {
        "id": "cafbf099"
      },
      "source": [
        "\n",
        "## 6) Embeddings* con **Autoencoder** (*red neuronal*)\n",
        "Intentaremos entrenar un **autoencoder denso** sobre los vectores TF‚ÄëIDF para obtener una representaci√≥n compacta.\n",
        "> Si **no** tienes `tensorflow` instalado, el bloque fallar√° y el *notebook* continuar√° con LSA.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "703d7123",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "703d7123",
        "outputId": "fb0019f5-53cb-4a20-e36a-29ee0757b1ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Entrenado autoencoder. Forma de embeddings: (10, 64)\n"
          ]
        }
      ],
      "source": [
        "# ---------------------------------------------------------------\n",
        "# Idea: entrenar una red neuronal (autoencoder) para comprimir los\n",
        "# vectores TF-IDF a un espacio latente (embeddings) y luego usar\n",
        "# ese espacio para b√∫squeda sem√°ntica.\n",
        "#   ‚Ä¢ Entrada  : vector TF-IDF de cada documento\n",
        "#   ‚Ä¢ Codificador (encoder): reduce dimensionalidad ‚Üí \"z\"\n",
        "#   ‚Ä¢ Decodificador (decoder): intenta reconstruir el TF-IDF original\n",
        "#   ‚Ä¢ P√©rdida : MSE entre entrada y salida (reconstrucci√≥n)\n",
        "# Al terminar, usamos SOLO el \"encoder\" para obtener los embeddings.\n",
        "# ===============================================================\n",
        "\n",
        "AE_EMBED_DIM = 64  # ‚á¶ Dimensi√≥n del embedding latente \"z\". (Prueba 32 / 64 / 128)\n",
        "EPOCHS = 40        # ‚á¶ √âpocas de entrenamiento. (M√°s alto = m√°s ajuste, riesgo de overfitting)\n",
        "BATCH_SIZE = 8     # ‚á¶ Tama√±o de batch. (S√∫belo si tienes GPU/CPU potente)\n",
        "\n",
        "# Pasamos de matriz dispersa (sparse) a densa (float32) para alimentar a Keras\n",
        "X_dense = X_tfidf.toarray().astype(\"float32\")\n",
        "\n",
        "try:\n",
        "    # Importamos TensorFlow/Keras dentro del try por si el entorno no lo tiene\n",
        "    import tensorflow as tf\n",
        "    from tensorflow import keras\n",
        "    from tensorflow.keras import layers\n",
        "\n",
        "    # Dimensi√≥n de entrada = # de t√©rminos/rasgos del TF-IDF\n",
        "    input_dim = X_dense.shape[1]\n",
        "\n",
        "    # ----- Definici√≥n del modelo -----\n",
        "    # Capa de entrada: vector TF-IDF por documento\n",
        "    inp = keras.Input(shape=(input_dim,))\n",
        "\n",
        "    # Encoder: capas densas que van \"apretando\" la info\n",
        "    x = layers.Dense(256, activation=\"relu\")(inp)   # 1¬™ capa oculta (no linealidad)\n",
        "    x = layers.Dense(128, activation=\"relu\")(x)     # 2¬™ capa oculta\n",
        "\n",
        "    # Bottleneck / Embedding: aqu√≠ vivimos en AE_EMBED_DIM dimensiones\n",
        "    # activation=None ‚Üí dejamos la representaci√≥n \"lineal\" (puedes probar 'tanh')\n",
        "    z = layers.Dense(AE_EMBED_DIM, activation=None, name=\"embedding\")(x)\n",
        "\n",
        "    # Decoder: intenta reconstruir el vector original desde \"z\"\n",
        "    x = layers.Dense(128, activation=\"relu\")(z)\n",
        "    # √öltima capa del decoder: dimensi√≥n = input_dim.\n",
        "    # activation=\"linear\" porque queremos reconstruir valores continuos del TF-IDF\n",
        "    out = layers.Dense(input_dim, activation=\"linear\")(x)\n",
        "\n",
        "    # Autoencoder completo: input ‚Üí reconstruction\n",
        "    autoenc = keras.Model(inp, out)\n",
        "\n",
        "    # Optimizador y p√©rdida:\n",
        "    #  - Adam(1e-3) suele converger bien en estos tama√±os\n",
        "    #  - MSE mide error de reconstrucci√≥n; tambi√©n podr√≠as probar MAE\n",
        "    autoenc.compile(optimizer=keras.optimizers.Adam(1e-3), loss=\"mse\")\n",
        "\n",
        "    # ----- Entrenamiento -----\n",
        "    # Entrenamos de forma no supervisada: entrada = objetivo\n",
        "    history = autoenc.fit(\n",
        "        X_dense, X_dense,\n",
        "        epochs=EPOCHS,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        verbose=0  # pon 1 si quieres ver la barra de progreso\n",
        "    )\n",
        "\n",
        "    # ----- Extraer el encoder para obtener embeddings -----\n",
        "    # Creamos un modelo que va de la entrada \"inp\" al cuello de botella \"z\"\n",
        "    encoder = keras.Model(inp, z)\n",
        "\n",
        "    # Embeddings para TODO el corpus (uno por documento)\n",
        "    X_ae = encoder.predict(X_dense, verbose=0)\n",
        "\n",
        "    ae_available = True\n",
        "    print(\"‚úÖ Entrenado autoencoder. Forma de embeddings:\", X_ae.shape)\n",
        "    # Ejemplo de salida: (n_documentos, AE_EMBED_DIM)\n",
        "\n",
        "except Exception as e:\n",
        "    # Si no hay TensorFlow/Keras o falla algo, seguimos con LSA.\n",
        "    ae_available = False\n",
        "    X_ae = None\n",
        "    print(\"‚ö†Ô∏è No se pudo usar TensorFlow/Keras. Continuaremos solo con LSA.\")\n",
        "    print(\"Detalle:\", e)\n",
        "\n",
        "# ---------------------------------------------------------------\n",
        "# Notas y sugerencias:\n",
        "# ‚Ä¢ Si ves sobre-ajuste (loss de entrenamiento muy baja pero mala\n",
        "#   recuperaci√≥n), baja EPOCHS, sube regularizaci√≥n (p.ej. layers.Dropout),\n",
        "#   o reduce la capacidad (menos neuronas).\n",
        "# ‚Ä¢ AE_EMBED_DIM muy chico puede perder info; muy grande puede memorizar.\n",
        "# ‚Ä¢ Puedes probar activaciones 'tanh' en z si planeas usar similitud coseno.\n",
        "# ‚Ä¢ Con GPU, puedes subir BATCH_SIZE para acelerar.\n",
        "# ---------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "196f0cc3",
      "metadata": {
        "id": "196f0cc3"
      },
      "source": [
        "## 7) √çndices de **b√∫squeda sem√°ntica**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "b64880da",
      "metadata": {
        "id": "b64880da"
      },
      "outputs": [],
      "source": [
        "# ---------------------------------------------------------------\n",
        "# Creamos √≠ndices k-Nearest Neighbors (kNN) usando la m√©trica de\n",
        "# distancia coseno (1 - similitud_coseno). Luego definimos:\n",
        "#   ‚Ä¢ embed_query(): c√≥mo convertir una consulta a vector seg√∫n el m√©todo\n",
        "#   ‚Ä¢ search(): recupera los top-k documentos m√°s similares y arma una tabla\n",
        "# ===============================================================\n",
        "\n",
        "# √çndices kNN con m√©trica coseno\n",
        "# - Para TF-IDF y LSA siempre tenemos matrices listas.\n",
        "# - Para AE solo si el autoencoder se entren√≥ (ae_available=True y X_ae no es None).\n",
        "idx_tfidf = NearestNeighbors(n_neighbors=5, metric=\"cosine\").fit(X_tfidf)\n",
        "idx_lsa   = NearestNeighbors(n_neighbors=5, metric=\"cosine\").fit(X_lsa)\n",
        "idx_ae    = NearestNeighbors(n_neighbors=5, metric=\"cosine\").fit(X_ae) if ae_available else None\n",
        "\n",
        "def embed_query(query: str, method: str = \"lsa\"):\n",
        "    \"\"\"\n",
        "    Convierte una consulta en su representaci√≥n vectorial seg√∫n el 'method'.\n",
        "\n",
        "    Flujo:\n",
        "      1) Limpia y normaliza la consulta (min√∫sculas, quita acentos, stopwords, etc.).\n",
        "      2) Vectoriza con el mismo TF-IDF entrenado sobre el corpus.\n",
        "      3) Proyecta:\n",
        "         - 'tfidf' ‚Üí se queda en el espacio TF-IDF.\n",
        "         - 'lsa'   ‚Üí aplica SVD entrenado (espacio sem√°ntico reducido).\n",
        "         - 'ae'    ‚Üí pasa por el encoder del autoencoder para obtener embeddings.\n",
        "    \"\"\"\n",
        "    # Normalizamos y removemos stopwords para alinear con el preprocesamiento de los documentos\n",
        "    q = remove_stopwords(query)\n",
        "\n",
        "    # Vectorizamos la consulta con el mismo TF-IDF (¬°importante usar el mismo vocabulario!)\n",
        "    v_tfidf = tfidf.transform([q])\n",
        "\n",
        "    if method == \"tfidf\":\n",
        "        # Devuelve vector en el espacio TF-IDF (matriz dispersa)\n",
        "        return v_tfidf\n",
        "    elif method == \"lsa\":\n",
        "        # Proyecci√≥n al espacio latente de LSA (dimensionalidad reducida)\n",
        "        return svd.transform(v_tfidf)\n",
        "    elif method == \"ae\" and ae_available:\n",
        "        # Pasamos a denso y obtenemos embeddings con el encoder del autoencoder\n",
        "        return encoder.predict(v_tfidf.toarray().astype(\"float32\"), verbose=0)\n",
        "    else:\n",
        "        # Errores comunes: pedir 'ae' cuando no se entren√≥; o m√©todo mal escrito\n",
        "        raise ValueError(\"M√©todo no v√°lido o AE no disponible\")\n",
        "\n",
        "def search(query: str, k: int = 3, method: str = \"lsa\") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Realiza una b√∫squeda sem√°ntica:\n",
        "      - Embebe la consulta con embed_query().\n",
        "      - Busca sus vecinos m√°s cercanos (top-k) en el √≠ndice correspondiente.\n",
        "      - Devuelve un DataFrame con m√©tricas y metadatos legibles.\n",
        "\n",
        "    Columnas del resultado:\n",
        "      ‚Ä¢ score(1-cos): distancia = 1 - similitud_coseno  ‚Üí **MENOR es mejor** (0 = id√©ntico)\n",
        "      ‚Ä¢ sim_cos     : similitud coseno                  ‚Üí **MAYOR es mejor** (1 = id√©ntico)\n",
        "      ‚Ä¢ id, titulo  : metadatos del documento recuperado\n",
        "      ‚Ä¢ snippet     : fragmento del contenido para inspecci√≥n r√°pida\n",
        "    \"\"\"\n",
        "    # 1) Embedding de la consulta en el espacio correcto\n",
        "    v = embed_query(query, method=method)\n",
        "\n",
        "    # 2) Elegimos el √≠ndice seg√∫n 'method' y recuperamos distancias e √≠ndices\n",
        "    if method == \"tfidf\":\n",
        "        dist, idxs = idx_tfidf.kneighbors(v, n_neighbors=k)\n",
        "    elif method == \"lsa\":\n",
        "        dist, idxs = idx_lsa.kneighbors(v, n_neighbors=k)\n",
        "    elif method == \"ae\":\n",
        "        # Si pidieron AE pero no hay √≠ndice (por no entrenar), esto dar√≠a error;\n",
        "        # asumimos que 'embed_query' lo control√≥ y solo llegamos aqu√≠ si AE est√° disponible.\n",
        "        dist, idxs = idx_ae.kneighbors(v, n_neighbors=k)\n",
        "    else:\n",
        "        raise ValueError(\"M√©todo de b√∫squeda desconocido\")\n",
        "\n",
        "    # 3) Construimos una tabla amigable con los resultados\n",
        "    rows = []\n",
        "    for d, i in zip(dist[0], idxs[0]):\n",
        "        rows.append({\n",
        "            \"score(1-cos)\": float(d),                 # 1 - coseno  ‚Üí m√°s bajo = mejor\n",
        "            \"sim_cos\": float(1.0 - d),                # coseno      ‚Üí m√°s alto = mejor\n",
        "            \"id\": int(df.iloc[i][\"id\"]),              # id del doc recuperado\n",
        "            \"titulo\": df.iloc[i][\"titulo\"],           # t√≠tulo del doc\n",
        "            \"snippet\": df.iloc[i][\"contenido\"].strip()[:180] + \"...\"  # vista previa\n",
        "        })\n",
        "\n",
        "    # 4) Regresamos un DataFrame ordenado como lo entrega kNN (mejor a peor)\n",
        "    return pd.DataFrame(rows)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7891ee88",
      "metadata": {
        "id": "7891ee88"
      },
      "source": [
        "## 8) Consultas de ejemplo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2237e381",
      "metadata": {
        "id": "2237e381"
      },
      "outputs": [],
      "source": [
        "#---------------------------------------------------------------\n",
        "# Objetivo: probar la b√∫squeda sem√°ntica con varias preguntas\n",
        "# t√≠picas del caso de uso \"FAQ corporativa\". Usaremos el m√©todo\n",
        "# LSA (espacio sem√°ntico reducido con SVD) y pediremos el top-3.\n",
        "# ===============================================================\n",
        "\n",
        "queries = [\n",
        "    # Cada elemento es una \"consulta\" del usuario final.\n",
        "    # Procuramos cubrir varias √°reas para ver si el buscador\n",
        "    # trae el documento correcto por significado (no por palabras exactas).\n",
        "    \"¬øC√≥mo pido vacaciones y cu√°ntos d√≠as tengo?\",                 # Esperado: doc de Vacaciones (id=1)\n",
        "    \"Necesito conectarme a la red interna desde casa\",            # Esperado: VPN/teletrabajo (id=2)\n",
        "    \"Quiero acceso a bases de datos productivas\",                 # Esperado: Accesos a BDs (id=10)\n",
        "    \"¬øQui√©n me ayuda con dashboards en Looker o Power BI?\",       # Esperado: Soporte BI (id=5)\n",
        "    \"Alta en cuentas de nube para un proyecto en GCP\"             # Esperado: Alta en Cloud (id=4)\n",
        "]\n",
        "\n",
        "# k = 3  ‚Üí Recupera los 3 documentos m√°s similares (top-3).\n",
        "# method = \"lsa\" ‚Üí La consulta se vectoriza con TF-IDF y se proyecta al\n",
        "#                  espacio sem√°ntico reducido por SVD (LSA).\n",
        "# En este espacio comparamos por coseno: cuanto m√°s cerca del 1, m√°s similar.\n",
        "\n",
        "for i, q in enumerate(queries, start=1):\n",
        "    print(f\"\\nüîé Consulta {i}: {q}\")\n",
        "\n",
        "    # La funci√≥n search() devuelve un DataFrame con:\n",
        "    # - 'score(1-cos)': distancia = 1 - coseno   ‚Üí **MENOR es mejor** (0 = id√©ntico).\n",
        "    # - 'sim_cos':      similitud coseno         ‚Üí **MAYOR es mejor** (1 = id√©ntico).\n",
        "    # - 'id':           id del documento recuperado.\n",
        "    # - 'titulo':       t√≠tulo del documento.\n",
        "    # - 'snippet':      primer fragmento del contenido para inspecci√≥n r√°pida.\n",
        "    res = search(q, k=3, method=\"lsa\")\n",
        "\n",
        "    # Recordatorio r√°pido para interpretar:\n",
        "    print(\"   Nota: sim_cos cercano a 1 = m√°s parecido; score(1-cos) cercano a 0 = mejor.\")\n",
        "\n",
        "    # Mostramos la tabla con los 3 mejores resultados seg√∫n la similitud coseno.\n",
        "    display(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f93c9f43",
      "metadata": {
        "id": "f93c9f43"
      },
      "source": [
        "## 9) Mini evaluaci√≥n de relevancia (Precision@k y MRR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6544447",
      "metadata": {
        "id": "e6544447"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ---------------------------------------------------------------\n",
        "# Usamos un \"golden set\" muy simple: para cada consulta definimos\n",
        "# cu√°l ser√≠a el ID del documento correcto (verdad terreno).\n",
        "# Luego calculamos dos m√©tricas:\n",
        "#   ‚Ä¢ Precision@k: ¬øaparece el doc correcto dentro del top-k?\n",
        "#   ‚Ä¢ MRR (Mean Reciprocal Rank): 1/rank del doc correcto.\n",
        "#      - Si el correcto est√° en 1er lugar ‚Üí 1.0\n",
        "#      - Si est√° en 2¬∫ ‚Üí 0.5; en 3¬∫ ‚Üí 0.333...; si no aparece ‚Üí 0.0\n",
        "# ===============================================================\n",
        "\n",
        "# \"golden\" aproximado: mapeamos consulta -> id de documento esperado\n",
        "gold = {\n",
        "    # Nota: queries[i] viene de la celda anterior.\n",
        "    # Este mapeo es solo para esta pr√°ctica (corpus peque√±o).\n",
        "    queries[0]: 1,   # Esperado: \"Pol√≠tica de Vacaciones\"\n",
        "    queries[1]: 2,   # Esperado: \"Acceso a VPN corporativa\"\n",
        "    queries[2]: 10,  # Esperado: \"Accesos a Bases de Datos\"\n",
        "    queries[3]: 5,   # Esperado: \"Soporte a Business Intelligence (BI)\"\n",
        "    queries[4]: 4,   # Esperado: \"Alta en Plataformas Cloud (GCP/Azure/AWS)\"\n",
        "}\n",
        "\n",
        "def precision_at_k(results_ids: List[int], relevant_id: int, k: int = 3) -> float:\n",
        "    \"\"\"\n",
        "    Devuelve 1.0 si el documento relevante aparece dentro de los primeros k resultados,\n",
        "    de lo contrario 0.0.\n",
        "    - results_ids: lista de IDs ordenados por similitud (top primero).\n",
        "    - relevant_id: ID del documento que consideramos la 'respuesta correcta'.\n",
        "    - k: corte de la lista (top-k).\n",
        "    \"\"\"\n",
        "    return 1.0 if relevant_id in results_ids[:k] else 0.0\n",
        "\n",
        "def reciprocal_rank(results_ids: List[int], relevant_id: int) -> float:\n",
        "    \"\"\"\n",
        "    Calcula el Reciprocal Rank (RR) para una consulta:\n",
        "    - Busca en qu√© posici√≥n (rank) aparece el ID relevante.\n",
        "    - Retorna 1/rank si se encuentra; 0.0 si no aparece en la lista.\n",
        "    \"\"\"\n",
        "    for rank, doc_id in enumerate(results_ids, start=1):\n",
        "        if doc_id == relevant_id:\n",
        "            return 1.0 / rank\n",
        "    return 0.0\n",
        "\n",
        "def evaluate(method: str = \"lsa\", k: int = 3) -> dict:\n",
        "    \"\"\"\n",
        "    Ejecuta la evaluaci√≥n para todas las consultas del 'golden' usando\n",
        "    el m√©todo de embeddings indicado (lsa, tfidf o ae si est√° disponible).\n",
        "\n",
        "    Flujo:\n",
        "    1) Para cada consulta q del golden:\n",
        "       - Recupera top-k resultados con search(q, k, method).\n",
        "       - Extrae la lista de IDs (ordenados por similitud).\n",
        "       - Calcula Precision@k y RR para esa consulta.\n",
        "    2) Promedia sobre todas las consultas ‚Üí Precision@k promedio y MRR.\n",
        "\n",
        "    Retorna:\n",
        "      {\"Precision@k\": <promedio>, \"MRR\": <promedio>}\n",
        "    \"\"\"\n",
        "    pks, mrrs = [], []\n",
        "    for q, rel_id in gold.items():\n",
        "        res = search(q, k=k, method=method)  # DataFrame con columnas: id, titulo, sim_cos, score(1-cos)...\n",
        "        ids = res[\"id\"].tolist()             # Extraemos solo los IDs en el orden retornado (mejor a peor).\n",
        "        pks.append(precision_at_k(ids, rel_id, k=k))\n",
        "        mrrs.append(reciprocal_rank(ids, rel_id))\n",
        "    return {f\"Precision@{k}\": float(np.mean(pks)), \"MRR\": float(np.mean(mrrs))}\n",
        "\n",
        "# ---------------------------------------------------------------\n",
        "# Ejecutamos la evaluaci√≥n con distintos m√©todos de embeddings.\n",
        "# Interpreta as√≠:\n",
        "#  - Valores m√°s altos son mejores (m√°x 1.0).\n",
        "#  - Diferencias peque√±as en corpus chico son normales.\n",
        "#  - En producci√≥n, usa m√°s consultas y juicios humanos.\n",
        "# ---------------------------------------------------------------\n",
        "print(\"Resultados (LSA):\", evaluate(\"lsa\", k=3))\n",
        "print(\"Resultados (TF-IDF):\", evaluate(\"tfidf\", k=3))\n",
        "if ae_available:\n",
        "    print(\"Resultados (Autoencoder):\", evaluate(\"ae\", k=3))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79048b11",
      "metadata": {
        "id": "79048b11"
      },
      "source": [
        "\n",
        "### Interpretaci√≥n r√°pida\n",
        "- **Precision@k** indica si el documento correcto aparece entre los *k* primeros resultados.\n",
        "- **MRR** (Mean Reciprocal Rank) promedia la inversa del *rank* del documento relevante. Valores m√°s altos ‚áí mejor.\n",
        "\n",
        "> En un entorno real, conviene usar un conjunto de validaci√≥n m√°s grande, *judgements* manuales o heur√≠sticos (por ejemplo, *click logs*), y comparar varios m√©todos (TF‚ÄëIDF / LSA / *embeddings* neuronales preentrenados).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "957eb66b",
      "metadata": {
        "id": "957eb66b"
      },
      "source": [
        "## 10) Playground: escribe tus propias consultas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8693cdfa",
      "metadata": {
        "id": "8693cdfa"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Escribe cualquier pregunta en lenguaje natural y recupera\n",
        "# los 3 documentos m√°s parecidos por significado usando LSA.\n",
        "# Puedes cambiar:\n",
        "#   ‚Ä¢ q: tu texto de consulta\n",
        "#   ‚Ä¢ k: cu√°ntos resultados quieres (top-k)\n",
        "#   ‚Ä¢ method: \"lsa\" | \"tfidf\" | \"ae\" (si el autoencoder est√° disponible)\n",
        "# ===============================================================\n",
        "\n",
        "q = \"Escribe aqu√≠ tu consulta libre, por ejemplo: necesito equipo de c√≥mputo nuevo\"\n",
        "\n",
        "# Ejecutamos la b√∫squeda sem√°ntica.\n",
        "# La funci√≥n search() regresa un DataFrame con estas columnas:\n",
        "#  - 'score(1-cos)': distancia = 1 - similitud coseno  ‚Üí **MENOR es mejor** (0 = id√©ntico).\n",
        "#  - 'sim_cos':      similitud coseno                   ‚Üí **MAYOR es mejor** (1 = id√©ntico).\n",
        "#  - 'id':           ID interno del documento.\n",
        "#  - 'titulo':       t√≠tulo del documento recuperado.\n",
        "#  - 'snippet':      fragmento del contenido para inspecci√≥n r√°pida.\n",
        "resultados = search(q, k=3, method=\"lsa\")\n",
        "\n",
        "# Mensaje recordatorio para interpretar correctamente las m√©tricas\n",
        "print(\"üîé Consulta libre:\", q)\n",
        "print(\"   Nota: sim_cos cercano a 1 = m√°s parecido; score(1-cos) cercano a 0 = mejor.\")\n",
        "\n",
        "# Mostramos la tabla con los top-k documentos\n",
        "display(resultados)\n",
        "\n",
        "# (Opcional) Vista ultra-resumida: t√≠tulos y similitud\n",
        "print(\"\\nResumen (t√≠tulo y similitud coseno):\")\n",
        "for _, row in resultados.iterrows():\n",
        "    print(f\" - [{row['id']:>2}] {row['titulo']}  |  sim_cos={row['sim_cos']:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93e4b0bb",
      "metadata": {
        "id": "93e4b0bb"
      },
      "source": [
        "\n",
        "---\n",
        "## 11) **Preguntas y ejercicios de comprensi√≥n**\n",
        "1. **Expl√≠calo con tus palabras:** ¬øQu√© diferencia hay entre los *embeddings* basados en **TF‚ÄëIDF**, **LSA** y  **Autoencoder**? ¬øCu√°l ser√≠a m√°s robusto ante sin√≥nimos?\n",
        "2. **Experimenta con dimensiones:** Cambia el valor de `n_components` en la celda de LSA (por ejemplo 32, 64, 128). ¬øC√≥mo var√≠an **Precision@k** y **MRR**? (Escribe el codigo debajo marcado con Experimento 2)\n",
        "3. **Red neuronal:** Modifica `AE_EMBED_DIM`, `EPOCHS` y `BATCH_SIZE` del autoencoder. ¬øMejora o empeora el desempe√±o? ¬øAumenta el *overfitting*?\n",
        "(Escribe el codigo debajo marcado con Experimento 3)\n",
        "4. **Ampl√≠a el corpus:** Agrega al *DataFrame* `df` al menos **5** documentos adicionales (por ejemplo, sobre *pol√≠tica de gastos*, *viajes*, *beneficios*). Re‚Äëentrena y comenta los cambios en resultados.\n",
        "5. **An√°lisis de relevancia:** Define **5 nuevas consultas** y una *golden truth* para cada una. Ejecuta la evaluaci√≥n y reporta m√©tricas con un breve comentario (2‚Äì3 l√≠neas).\n",
        "\n",
        "> **Entrega:** Sube este *notebook* con tus respuestas (en celdas Markdown) y las m√©tricas obtenidas tras tus experimentos.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TRrX2Ggw2emQ"
      },
      "id": "TRrX2Ggw2emQ",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}